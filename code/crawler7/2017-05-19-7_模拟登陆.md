---
layout: post
categories: [crawler]
title: 模拟登陆
date: 2117-05-20
author: TTyb
desc: "7.模拟登陆"
showdate: 2017-05-20
---

前面学习了如何在 `get` 的时候想服务器发送多变的请求数据，从而达到搜索的效果，而实际上 `搜索是简单的登陆` ！所以本文将要介绍如何向百度服务器发送 `post` 数据，从而达到模拟登陆百度的效果。

>1. 首先打开 `firefox` 浏览器，清除网页所有的历史纪录，这是为了防止以前的 `Cookie` 影响服务器返回的数据。
>2. `F12` 打开 `firebug` ，进入百度首页，点击 **网络** -> **清除** ,这是为了删掉打开百度首页而弹出来的 `html`，方便后面的查找 `html` 数据。
>3. 点击登陆按钮，依次填写账号、密码、验证码，点击 **登陆** ，在 `firebug` 中点击 `保持` ，这是为了防止登陆成功后，登陆表单的 `html` 被清除。

在 `firebug` 中，找到如下一行 `POST?login` ：

<img  src="/img/crawler7/result1.jpg"/>

点击前面的 `+` 号 -> `post` ，可以看到提交的表单，这个就是点击登陆后，网页向百度服务器后端发送的 **登陆请求表单**，表单中包含了 **账号**、**密码**、**其他** 等信息：

<img  src="/img/crawler7/result2.jpg"/>

如果百度后台认为此 **登陆表单请求** 是正确的后，会在 **头信息** -> **响应头信息** 中返回一个 `Set-Cookie` 。当我们登陆成功后，关闭浏览器，下次再打开浏览器的时候发现百度还是处于一种登陆的状态，这就是和 `Cookie` 有关。在百度登陆成功后会返回一个 `Cookie` 储存到浏览器中，下次再打开百度的时候，浏览器中的 **头信息** -> **请求头信息** 中会携带一个 `Cookie` ，这个 `Cookie` 就是百度服务器判断你以前是否登陆过百度。而这个 `Cooike` 就是 `Set-Cookie` 加工而来的！那么重点来了，如果要用代码模拟登陆百度，应该要具备以下几个步骤：

>1. 构造请求表单
>2. 请求成功后获取 `Cookie` (这个 `Cookie` 并非 `Set-Cookie`)
>3. 在请求头部 `header` 中携带这个 `Cookie` ，就可以以登陆过后的身份访问百度

原理讲清楚了，那么下面开始实践！

### 构造请求表单

在上面的 `POST?login` 中发现百度的请求表单还是挺多的，那么如何表单中判断哪些是变化的那些事不变的？再一次清空 `firefox` 的全部历史纪录，清除 `firebug` 的 `html` ，重新在百度首页点击 **登陆** ，填写 **账号**、**错误的密码**、**验证码**，复制 `POST?login` 中的 `post` 信息下来，然后重复前面的步骤，就可以得到很多 `post` 信息，拿出来对比就可以知道哪些信息是变化的了。这里要解释一下为什么要填写 **错误的密码**，因为密码错误啦，登陆框就会一直都在啊，免去了清除 **全部历史纪录** 和清除 `html` 的步骤。最后对比的情况如下：

<img  src="/img/crawler7/result3.jpg"/>

可以发现，请求的表单有

```
staticpage
charset
token
tpl
subpro
apiver
tt
codestring
safeflg
u
isPhone
detect
gid
quick_user
logintype
logLoginType
idc
loginmerge
splogin
username
password
verifycode
mem_pass
rsakey
crypttype
ppui_logintime
countrycode
fp_uid
dv
callback
```

其中，被红框框起来的表单是多次请求变话的：

```
callback
tt
token
ppui_logintime
rsakey
verifycode
```

其中很明显可以看出来的是:

>1. `tt` 时间戳
>2. `verifycode` 验证码

那么就剩下几个请求表单还暂时无法得知，首先查找 `callback`：

```
>1. 在 `firebug` 中勾选脚本，点击 `{}`
>2. 搜索中勾选 **多个文件**
>3. 在搜索框中搜索 `callback`
```

<img  src="/img/crawler7/result4.jpg"/>

一直搜索，最后发现 `callback` 和 `getUniqueId` 的生成有关：

<img  src="/img/crawler7/result5.jpg"/>

那么换着 `getUniqueId` 来搜索，得到如下 `javascrip` 代码：

```
e.getUniqueId = function (e) {
return e + Math.floor(2147483648 * Math.random()).toString(36)
},
```

和上面的整理起来，那么 `callback` 的生成代码为：

```
function callback(){
        return 'bd__cbs__'+Math.floor(2147483648 * Math.random()).toString(36)
    }
```



<img  src="/img/crawler7/result6.jpg"/>

# 练习

```
增加百度翻页的效果，即可以选择抓取第2页、第3页等等
```

# 源码

<a href="/code/crawler6/crawler6.py" target="_blank">crawler6.py</a>

<a href="/code/crawler6/answer.py" target="_blank">练习答案</a>